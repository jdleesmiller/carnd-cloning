{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import platform\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "\n",
    "from common import * \n",
    "import preprocess\n",
    "import model_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "\n",
    "The full inception model is too slow for real time use on my laptop, so I am just using the first few layers.\n",
    "\n",
    "Loading the whole inception model is also very slow, so cut out only the weights we need and save them for loading later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inception\n",
    "import model_io\n",
    "\n",
    "if not os.path.exists(BASE_MODEL_JSON_FILE):\n",
    "    model_io.save_model(\n",
    "        BASE_MODEL_JSON_FILE,\n",
    "        BASE_MODEL_WEIGHTS_FILE,\n",
    "        inception.make_cut_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_io.load_base_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "- Correct the image file paths, since I have several driving logs in different folders.\n",
    "- Smooth the control inputs. The input from me is quite spikey, because all I can do is press a button or not. This seems like it would make learning quite difficult, so apply smoothing.\n",
    "- Bottleneck the features to make training reasonably fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck folder exists in data/ccw_1 ; just binding.\n",
      "Bottleneck folder exists in data/cw_1 ; just binding.\n",
      "Bottleneck folder exists in data/ccw_2 ; just binding.\n",
      "Bottleneck folder exists in data/cw_2 ; just binding.\n",
      "Bottleneck folder exists in data/ccw_recover_from_right_1 ; just binding.\n",
      "Bottleneck folder exists in data/ccw_recover_from_left_1 ; just binding.\n",
      "Bottleneck folder exists in data/cw_recover_from_right_1 ; just binding.\n",
      "Bottleneck folder exists in data/cw_recover_from_left_1 ; just binding.\n",
      "                                        center_image  \\\n",
      "0  data/ccw_1/IMG/center_2016_12_08_21_38_10_346.jpg   \n",
      "1  data/ccw_1/IMG/center_2016_12_08_21_38_10_462.jpg   \n",
      "2  data/ccw_1/IMG/center_2016_12_08_21_38_10_578.jpg   \n",
      "3  data/ccw_1/IMG/center_2016_12_08_21_38_10_678.jpg   \n",
      "4  data/ccw_1/IMG/center_2016_12_08_21_38_10_779.jpg   \n",
      "\n",
      "                                        left_image  \\\n",
      "0  data/ccw_1/IMG/left_2016_12_08_21_38_10_346.jpg   \n",
      "1  data/ccw_1/IMG/left_2016_12_08_21_38_10_462.jpg   \n",
      "2  data/ccw_1/IMG/left_2016_12_08_21_38_10_578.jpg   \n",
      "3  data/ccw_1/IMG/left_2016_12_08_21_38_10_678.jpg   \n",
      "4  data/ccw_1/IMG/left_2016_12_08_21_38_10_779.jpg   \n",
      "\n",
      "                                        right_image  steering_angle  throttle  \\\n",
      "0  data/ccw_1/IMG/right_2016_12_08_21_38_10_346.jpg             0.0       0.0   \n",
      "1  data/ccw_1/IMG/right_2016_12_08_21_38_10_462.jpg             0.0       0.0   \n",
      "2  data/ccw_1/IMG/right_2016_12_08_21_38_10_578.jpg             0.0       0.0   \n",
      "3  data/ccw_1/IMG/right_2016_12_08_21_38_10_678.jpg             0.0       0.0   \n",
      "4  data/ccw_1/IMG/right_2016_12_08_21_38_10_779.jpg             0.0       0.0   \n",
      "\n",
      "   brake     speed                    time dataset  smooth_steering_angle_1  \\\n",
      "0      0  0.000078 2016-12-08 21:38:10.346   ccw_1                -0.015240   \n",
      "1      0  0.000080 2016-12-08 21:38:10.462   ccw_1                -0.017114   \n",
      "2      0  0.000083 2016-12-08 21:38:10.578   ccw_1                -0.019219   \n",
      "3      0  0.000079 2016-12-08 21:38:10.678   ccw_1                -0.021241   \n",
      "4      0  0.000080 2016-12-08 21:38:10.779   ccw_1                -0.023498   \n",
      "\n",
      "   smooth_throttle_1  smooth_brake_1  smooth_steering_angle_gaussian_3  \\\n",
      "0           0.101388             0.0                          0.000000   \n",
      "1           0.113858             0.0                          0.000000   \n",
      "2           0.127863             0.0                          0.000000   \n",
      "3           0.141310             0.0                         -0.000011   \n",
      "4           0.156328             0.0                         -0.000051   \n",
      "\n",
      "   smooth_throttle_gaussian_3  smooth_brake_gaussian_3  \\\n",
      "0                    0.000010                        0   \n",
      "1                    0.000060                        0   \n",
      "2                    0.000240                        0   \n",
      "3                    0.000788                        0   \n",
      "4                    0.002282                        0   \n",
      "\n",
      "   smooth_steering_angle_gaussian_5  smooth_throttle_gaussian_5  \\\n",
      "0                         -0.000522                    0.008699   \n",
      "1                         -0.000725                    0.011303   \n",
      "2                         -0.001170                    0.016886   \n",
      "3                         -0.001935                    0.026174   \n",
      "4                         -0.003136                    0.040183   \n",
      "\n",
      "   smooth_brake_gaussian_5             bottleneck_features  \n",
      "0                        0  data/ccw_1/bottleneck/0000.npz  \n",
      "1                        0  data/ccw_1/bottleneck/0001.npz  \n",
      "2                        0  data/ccw_1/bottleneck/0002.npz  \n",
      "3                        0  data/ccw_1/bottleneck/0003.npz  \n",
      "4                        0  data/ccw_1/bottleneck/0004.npz  \n"
     ]
    }
   ],
   "source": [
    "log = pd.concat([\n",
    "    preprocess.run('data/ccw_1'),\n",
    "    preprocess.run('data/cw_1'),\n",
    "    preprocess.run('data/ccw_2'),\n",
    "    preprocess.run('data/cw_2'),\n",
    "    preprocess.run('data/ccw_recover_from_right_1'),\n",
    "    preprocess.run('data/ccw_recover_from_left_1'),\n",
    "    preprocess.run('data/cw_recover_from_right_1'),\n",
    "    preprocess.run('data/cw_recover_from_left_1')\n",
    "])\n",
    "print(log.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>speed</th>\n",
       "      <th>steering_angle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ccw_1</th>\n",
       "      <td>1284</td>\n",
       "      <td>22.558356</td>\n",
       "      <td>-0.043736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccw_2</th>\n",
       "      <td>2882</td>\n",
       "      <td>8.833225</td>\n",
       "      <td>-0.041838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccw_recover_from_left_1</th>\n",
       "      <td>1405</td>\n",
       "      <td>11.775736</td>\n",
       "      <td>0.050748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccw_recover_from_right_1</th>\n",
       "      <td>1361</td>\n",
       "      <td>10.212416</td>\n",
       "      <td>-0.123761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cw_1</th>\n",
       "      <td>850</td>\n",
       "      <td>28.594668</td>\n",
       "      <td>0.018874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cw_2</th>\n",
       "      <td>2391</td>\n",
       "      <td>9.972545</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cw_recover_from_left_1</th>\n",
       "      <td>1550</td>\n",
       "      <td>10.484323</td>\n",
       "      <td>0.128920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cw_recover_from_right_1</th>\n",
       "      <td>1721</td>\n",
       "      <td>8.972610</td>\n",
       "      <td>0.017962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           len      speed  steering_angle\n",
       "dataset                                                  \n",
       "ccw_1                     1284  22.558356       -0.043736\n",
       "ccw_2                     2882   8.833225       -0.041838\n",
       "ccw_recover_from_left_1   1405  11.775736        0.050748\n",
       "ccw_recover_from_right_1  1361  10.212416       -0.123761\n",
       "cw_1                       850  28.594668        0.018874\n",
       "cw_2                      2391   9.972545        0.036800\n",
       "cw_recover_from_left_1    1550  10.484323        0.128920\n",
       "cw_recover_from_right_1   1721   8.972610        0.017962"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_dataset():\n",
    "    groups = log.groupby('dataset')\n",
    "    totals = groups['center_image'].agg([len])\n",
    "    mean_speed = groups['speed'].mean()\n",
    "    mean_steering_angle = groups['steering_angle'].mean()\n",
    "    return pd.concat([totals, mean_speed, mean_steering_angle], axis=1)\n",
    "summarize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "I tried two types of smoothing:\n",
    "\n",
    "- Exponential smoothing: an exponential weighted moving average\n",
    "- Gaussian smoothing: a 1D gaussian filter\n",
    "\n",
    "Both seem to track pretty well, but the gaussian smoothing is better at preserving the mean steering angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_smooth_steering_angle():\n",
    "    df = log[['time', 'steering_angle', 'smooth_steering_angle_1', 'smooth_steering_angle_gaussian_3']]\n",
    "    df = df[:600]\n",
    "    df = df.set_index(['time'])\n",
    "    df.plot(figsize=(12, 6))\n",
    "plot_smooth_steering_angle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steering Angle Bias\n",
    "\n",
    "We don't want a lot of bias in the training data. Or maybe this isn't that important... I don't really know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('raw steering angle bias:', np.mean(log['steering_angle']))\n",
    "print('exponentially smoothed steering angle bias:', np.mean(log['smooth_steering_angle_1']))\n",
    "print('gaussian smoothed steering angle bias:', np.mean(log['smooth_steering_angle_gaussian_5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bottleneck_output(num_images, num_channels, image_stride=50):\n",
    "    fig, axes = plt.subplots(num_images, num_channels,\n",
    "                             figsize=(2*num_channels, 2*num_images),\n",
    "                             sharex=True, sharey=True)\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_channels):\n",
    "            index = i * image_stride\n",
    "            image = np.load(log['bottleneck_features'].values[i])['center_image']\n",
    "            axes[i][j].imshow(image[:,:,j], cmap='gray')\n",
    "plot_bottleneck_output(3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothed Steering Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def steering_angle_to_radians(steering_angle):\n",
    "    \"\"\"\n",
    "    The recorded steering angle ranges from -1 to 1.\n",
    "    In the sim, it gives values from -25 degrees to 25 degrees.\n",
    "    \"\"\"\n",
    "    return math.radians(steering_angle * 25.0)\n",
    "\n",
    "def draw_steering_angle(image, steering_angle, color, thickness=2):\n",
    "    bottom_x = image.shape[1] / 2.0\n",
    "    bottom_y = image.shape[0]\n",
    "    radius = bottom_y / 2.0\n",
    "    steering_angle_radians = steering_angle_to_radians(steering_angle)\n",
    "    top_x = bottom_x + radius * math.sin(steering_angle_radians)\n",
    "    top_y = bottom_y - radius * math.cos(steering_angle_radians)\n",
    "    bottom_x, bottom_y = int(round(bottom_x)), int(round(bottom_y))\n",
    "    top_x, top_y = int(round(top_x)), int(round(top_y))\n",
    "    cv2.line(image, (bottom_x, bottom_y), (top_x, top_y), color, thickness)\n",
    "\n",
    "def make_steering_movie(\n",
    "    filestem,\n",
    "    log,\n",
    "    smoothed_steering_angle_column,\n",
    "    predicted_steering_angle_column=None):\n",
    "    \n",
    "    if platform.system() == 'Linux':\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        filename = filestem + '.avi'\n",
    "    else:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')        \n",
    "        filename = filestemp + '.mp4'\n",
    "    \n",
    "    input_color = [0, 0, 255]\n",
    "    smoothed_color = [0, 255, 0]\n",
    "    predicted_color = [255, 0, 0]\n",
    "    video = cv2.VideoWriter(filename, fourcc, 10, IMAGE_SHAPE[0:2][::-1])\n",
    "    for i in range(len(log)):\n",
    "        if i % 50 == 0:\n",
    "            print('frame', i)\n",
    "        image = imread(log['center_image'].values[i])\n",
    "        steering_angle = log['steering_angle'].values[i]\n",
    "        draw_steering_angle(image, steering_angle, input_color)\n",
    "\n",
    "        smoothed_steering_angle = log[smoothed_steering_angle_column].values[i]\n",
    "        draw_steering_angle(image, smoothed_steering_angle, smoothed_color)\n",
    "        \n",
    "        if predicted_steering_angle_column is not None:\n",
    "            predicted_steering_angle = log[predicted_steering_angle_column].values[i]\n",
    "            draw_steering_angle(image, predicted_steering_angle, predicted_color)\n",
    "\n",
    "        cv2.putText(image, log['center_image'].values[i],\n",
    "                    (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 0)\n",
    "            \n",
    "        video.write(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    video.release()\n",
    "    \n",
    "for dataset in log['dataset'].unique():\n",
    "    make_steering_movie(os.path.join('data', dataset, 'check'),\n",
    "                        log[log['dataset'] == dataset][0:100],\n",
    "                        'smooth_steering_angle_1')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "- I put a 1x1 convolution up front to reduce the depth, in order to make the model a more manageable size.\n",
    "\n",
    "## Experiments with Unsmoothed Steering Angles\n",
    "\n",
    "- Tried just adding a linear model (32--128 units, L2 regularization with weights 0.001--0.01) after the 1x1 convolution, but validation loss generally bottomed out at about MSE 0.04, which is too high. It also tended to diverge, at least with the Adam optimizer.\n",
    "- Tried adding a hidden layer (32-128 units) with ReLU activation and dropout before the linear layer, but that seemed to just predict a small constant steering angle most of the time. Maybe a \"dying relus\" problem. It seems you can get an MSE around 0.05 by just predicting a constant near zero all the time.\n",
    "- So I tried tanh activation instead, but that did not seem to help.\n",
    "- I switched back to L2 regularization with ReLUs, which did a bit better but still understeered.\n",
    "- I think the problem is that it's too easy to just ignore my occasional steering inputs (key presses).\n",
    "\n",
    "## Experiments with Smoothed Steering Angles\n",
    "\n",
    "- Tried the linear model again. No longer predicting constants, but it starts overfitting (increase in validation loss) after only a couple of epochs. Probably going to need something more expressive.\n",
    "- Tried adding hidden layer (32 units) with ReLU activation and L2 regularization (weight 0.01). Still mostly predicting a small constant.\n",
    "- Tried tanh activation on the hidden layer. Now it seems much happier: getting to the bridge and MSE 0.015 with nb_filter=64, nb_hidden=32 and l2_weight=0.01. Still understeering a bit on gentler bends.\n",
    "- Tried reducing L2 weight to 0.005. That seemed to slow down training quite a lot; got to MSE 0.017 after 16 epochs. Still understeering and weaving a bit.\n",
    "- Tried mean absolute error instead of mean squared error, since all of the errors are actually pretty small. New record on first run: made it to the turnout but didn't turn left. MAE 0.0611. Some weaving, but much less understeer. Much better fit in the steering prediction plot; good to see that better fit corresponds to better performance in this case. Adam optimizer diverged after 3 epochs, however.\n",
    "- Tried increasing regularization back to 0.01. That seems to make it get stuck on a constant again.\n",
    "- Tried putting regularization back to 0.005 but using Adagrad instead of Adam. Still getting stuck. Subsequent runs with Adam also getting stuck. Looks like I just got lucky that first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steering_model = model.build(\n",
    "    input_shape=np.load(log['bottleneck_features'].values[0])['center_image'].shape,\n",
    "    nb_filter=64,\n",
    "    nb_hidden=32,\n",
    "    l2_weight=0.005,\n",
    "    optimizer='adam'\n",
    "#     drop_prob=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = model.train(\n",
    "    steering_model, log,\n",
    "    label_column='smooth_steering_angle_gaussian_3',\n",
    "    test_size=0.2,\n",
    "    nb_epoch=20,\n",
    "    batch_size=128,\n",
    "    side_camera_bias=None,\n",
    "    save_stem='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model with best validation loss\n",
    "steering_model = model_io.load_model('model.json', 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log['predicted_steering_angle'] = steering_model.predict_generator(\n",
    "    model.generate_data(log),\n",
    "    val_samples=len(log)\n",
    ").flatten()\n",
    "print('raw MSE',\n",
    "    ((log['steering_angle'] - log['predicted_steering_angle'])**2).mean())\n",
    "print('smoothed MSE',\n",
    "    ((log['smooth_steering_angle_gaussian_3'] - log['predicted_steering_angle'])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_predicted_steering_angle():\n",
    "    df = log[['time', 'steering_angle', 'smooth_steering_angle_gaussian_3', 'predicted_steering_angle']]\n",
    "    df = df[:600]\n",
    "    df = df.set_index(['time'])\n",
    "    df.plot(figsize=(12, 6))\n",
    "plot_predicted_steering_angle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_steering_movie('test', log[0:500], 'smooth_steering_angle_1', 'predicted_steering_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# From http://stackoverflow.com/a/40623158/2053820\n",
    "def dict_product(dicts):\n",
    "    \"\"\"\n",
    "    >>> list(dict_product(dict(number=[1,2], character='ab')))\n",
    "    [{'character': 'a', 'number': 1},\n",
    "     {'character': 'a', 'number': 2},\n",
    "     {'character': 'b', 'number': 1},\n",
    "     {'character': 'b', 'number': 2}]\n",
    "    \"\"\"\n",
    "    return (dict(zip(dicts, x)) for x in itertools.product(*dicts.values()))\n",
    "\n",
    "def make_model_key_stem(key):\n",
    "    stem = os.path.join('models', 'grid_model_')\n",
    "    for param, value in key.items():\n",
    "        if value is None: value = ''\n",
    "        stem += param + '-' + str(value)\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb_hidden': 64, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.001, 'nb_epoch': 30, 'batch_size': 128, 'nb_filter': 64, 'side_camera_bias': None, 'optimizer': 'adam', 'version': 2}\n",
      "Running...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 17, 37, 64)    16448       convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 40256)         0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 64)            2576448     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             65          dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2592961\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s - loss: 0.2929 - val_loss: 8.8844\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s - loss: 9.0154 - val_loss: 8.8768\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s - loss: 9.0108 - val_loss: 8.8217\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s - loss: 8.9592 - val_loss: 8.7630\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s - loss: 8.9040 - val_loss: 8.7022\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s - loss: 8.8468 - val_loss: 8.6402\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s - loss: 8.7882 - val_loss: 8.5774\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s - loss: 8.7285 - val_loss: 8.5139\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s - loss: 8.6680 - val_loss: 8.4500\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s - loss: 8.6069 - val_loss: 8.3857\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s - loss: 8.5451 - val_loss: 8.3211\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s - loss: 8.4828 - val_loss: 8.2563\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s - loss: 8.4201 - val_loss: 8.1914\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s - loss: 8.3570 - val_loss: 8.1262\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s - loss: 8.2936 - val_loss: 8.0610\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s - loss: 8.2298 - val_loss: 7.9957\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s - loss: 8.1657 - val_loss: 7.9302\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s - loss: 8.1014 - val_loss: 7.8648\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s - loss: 8.0369 - val_loss: 7.7992\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s - loss: 7.9721 - val_loss: 7.7336\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s - loss: 7.9072 - val_loss: 7.6680\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s - loss: 7.8421 - val_loss: 7.6024\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s - loss: 7.7768 - val_loss: 7.5367\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s - loss: 7.7114 - val_loss: 7.4710\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s - loss: 7.6458 - val_loss: 7.4053\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s - loss: 7.5802 - val_loss: 7.3396\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s - loss: 7.5145 - val_loss: 7.2739\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s - loss: 7.4486 - val_loss: 7.2081\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s - loss: 7.3827 - val_loss: 7.1424\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s - loss: 7.3168 - val_loss: 7.0767\n",
      "{'nb_hidden': 64, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.001, 'nb_epoch': 30, 'batch_size': 128, 'nb_filter': 64, 'side_camera_bias': None, 'optimizer': 'adam', 'version': 3}\n",
      "Running...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_2 (Convolution2D)  (None, 17, 37, 64)    16448       convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 40256)         0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 64)            2576448     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             65          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2592961\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s - loss: 0.6719 - val_loss: 9.6112\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s - loss: 9.7430 - val_loss: 9.5910\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s - loss: 9.7259 - val_loss: 9.5351\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s - loss: 9.6736 - val_loss: 9.4758\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s - loss: 9.6182 - val_loss: 9.4147\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s - loss: 9.5608 - val_loss: 9.3524\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s - loss: 9.5021 - val_loss: 9.2894\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s - loss: 9.4424 - val_loss: 9.2258\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s - loss: 9.3818 - val_loss: 9.1617\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s - loss: 9.3206 - val_loss: 9.0973\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s - loss: 9.2587 - val_loss: 9.0326\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s - loss: 9.1964 - val_loss: 8.9677\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s - loss: 9.1336 - val_loss: 8.9025\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s - loss: 9.0703 - val_loss: 8.8373\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s - loss: 9.0068 - val_loss: 8.7720\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s - loss: 8.9429 - val_loss: 8.7066\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s - loss: 8.8788 - val_loss: 8.6412\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s - loss: 8.8145 - val_loss: 8.5757\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s - loss: 8.7499 - val_loss: 8.5101\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s - loss: 8.6851 - val_loss: 8.4445\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s - loss: 8.6202 - val_loss: 8.3789\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s - loss: 8.5550 - val_loss: 8.3132\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s - loss: 8.4897 - val_loss: 8.2475\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s - loss: 8.4243 - val_loss: 8.1818\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s - loss: 8.3588 - val_loss: 8.1161\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s - loss: 8.2931 - val_loss: 8.0504\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s - loss: 8.2274 - val_loss: 7.9847\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s - loss: 8.1616 - val_loss: 7.9190\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s - loss: 8.0957 - val_loss: 7.8532\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d12d5fbb63be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-d12d5fbb63be>\u001b[0m in \u001b[0;36msearch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mside_camera_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'side_camera_bias'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             save_stem=key_stem)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msteering_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_h5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# best weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/carnd/cloning/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, log, label_column, test_size, nb_epoch, batch_size, side_camera_bias, save_stem)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1450\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1452\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def search():\n",
    "    results_file = 'grid.pickle'\n",
    "    if os.path.isfile(results_file):\n",
    "        with open(results_file, 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "    else:\n",
    "        results = {}\n",
    "    \n",
    "    keys = {\n",
    "        'version': [2,3,4],\n",
    "        'nb_epoch': [30],\n",
    "        'side_camera_bias': [None],\n",
    "        'label_column': ['smooth_steering_angle_gaussian_3'],\n",
    "        'batch_size': [128],\n",
    "        'nb_filter': [64, 128],\n",
    "        'nb_hidden': [64, 32],\n",
    "        'l2_weight': [0.001, 0.005, 0.01],\n",
    "        'optimizer': ['adam', 'adagrad']\n",
    "    }\n",
    "    \n",
    "    input_shape = np.load(log['bottleneck_features'].values[0])['center_image'].shape\n",
    "        \n",
    "    for key in dict_product(keys):\n",
    "        print(key)\n",
    "        frozen_key = frozenset(key.items())\n",
    "        if frozen_key in results:\n",
    "            continue\n",
    "        print('Running...')\n",
    "        \n",
    "        key_stem = make_model_key_stem(key)\n",
    "        model_json = key_stem + '.json'\n",
    "        model_weights_h5 = key_stem + '.h5'\n",
    "        \n",
    "        key = key.copy()\n",
    "        del key['version']\n",
    "        \n",
    "        steering_model = model.build(\n",
    "            input_shape,\n",
    "            nb_filter=key.pop('nb_filter'),\n",
    "            nb_hidden=key.pop('nb_hidden'),\n",
    "            l2_weight=key.pop('l2_weight'),\n",
    "            optimizer=key.pop('optimizer'))\n",
    "        \n",
    "        history = model.train(\n",
    "            steering_model,\n",
    "            log,\n",
    "            label_column=key.pop('label_column'),\n",
    "            test_size=0.2,\n",
    "            nb_epoch=key.pop('nb_epoch'),\n",
    "            batch_size=key.pop('batch_size'),\n",
    "            side_camera_bias=key.pop('side_camera_bias'),\n",
    "            save_stem=key_stem)\n",
    "        \n",
    "        steering_model.load_weights(model_weights_h5) # best weights\n",
    "        \n",
    "        model_io.save_model(model_json, model_weights_h5, steering_model)\n",
    "                    \n",
    "        results[frozen_key] = {\n",
    "            'history': history.history,\n",
    "            'model_json': model_json,\n",
    "            'model_weights_h5': model_weights_h5\n",
    "        }\n",
    "        \n",
    "        with open(results_file, 'wb') as f:\n",
    "            pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return results  \n",
    "\n",
    "grid = search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO\n",
    "\n",
    "- there is a wiggle in ccw_recover_from_left_1 at about 0:42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize_grid(grid, val_loss_threshold):\n",
    "    \"\"\"\n",
    "    Print out the more promising hyperparameters from a search, according to\n",
    "    validation loss.\n",
    "    \"\"\"\n",
    "    best_val_loss = 1e9\n",
    "    best_params = None\n",
    "    items = sorted(grid, key = lambda k: min(grid[k]['history']['val_loss']))\n",
    "    for frozen_key in items:\n",
    "        value = grid[frozen_key]\n",
    "        key = dict(frozen_key)\n",
    "        val_loss = value['history']['val_loss']\n",
    "        min_val_loss = min(val_loss)\n",
    "        nb_epochs = len(val_loss)\n",
    "        if min_val_loss < val_loss_threshold:\n",
    "            print(key, min_val_loss, nb_epochs)\n",
    "            print('rm -f model.json model.h5')\n",
    "            print('cp', value['model_json'], 'model.json')\n",
    "            print('cp', value['model_h5'], 'model.h5')\n",
    "            print('python drive.py model.json')\n",
    "            print()\n",
    "        if min_val_loss < best_val_loss:\n",
    "            best_val_loss = min_val_loss\n",
    "            best_params = key\n",
    "    print('BEST:', best_params, best_val_loss)\n",
    "summarize_grid(grid, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_file = 'grid.pickle'\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'rb') as f:\n",
    "        grid = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
