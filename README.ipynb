{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "## Overall Approach\n",
    "\n",
    "- Take the image preprocessing and the first ~~forty four~~ twelve layers (convolutions ~~plus two inception modules~~) from the InceptionV3 network --- the `base_model`.\n",
    "- Apply a 3-sigma Gaussian filter to the steering angles in the training data to smooth them, because my keyboard input was quite spikey.\n",
    "- Also use the udacity training dataset, which was released after I collected my own data (but do not apply smoothing to it). \n",
    "- Run the images through the base model to produce bottleneck features.\n",
    "  - Also use the left and right camera images and bias the steering angle by 1.5 degrees toward the center.\n",
    "  - Also reflect the images horizontally and flip the sign of the angle.\n",
    "  - That givess 6 features per frame in total.\n",
    "- Train a deep neural net (see architecture below) with the bottleneck features as inputs.\n",
    "- Evaluate the model for roughly 100 different sets of hyperparameters (see Appendix) to produce a shortlist of about 50 that have below average Mean Absolute Error (MAE). (Networks trained on MAE were found to be better empirically.)\n",
    "- Evaluate the shortlist on the simulator. The networks with the lowest MAE were not always the ones that performed the best on the track.\n",
    "\n",
    "## Resubmission Notes\n",
    "\n",
    "- The model failed to drive around the track on the reviewer's computer. My best guess is that it was a performance problem, because I saw similar failures when I ran the code on an older laptop. To investigate, I added added timing info into my drive.py output (this was on my faster laptop):\n",
    "```\n",
    "dt: 0.177s\tdt_base: 0.174s\tsa: 0.014\tthrottle=0.172\tnew throttle=0.315\n",
    "dt: 0.174s\tdt_base: 0.169s\tsa: 0.014\tthrottle=0.179\tnew throttle=0.311\n",
    "dt: 0.167s\tdt_base: 0.165s\tsa: 0.014\tthrottle=0.179\tnew throttle=0.311\n",
    "dt: 0.151s\tdt_base: 0.147s\tsa: 0.038\tthrottle=0.173\tnew throttle=0.221\n",
    "```\n",
    "Here the `dt` is the total prediction time per frame and the `dt_base` is how long it takes to pass the frame through the base model. Clearly the base model dominates the total frame time. On my faster laptop, frame times were about 0.15s, which seemed to work fine, but on my slower laptop, it was around 0.5s per frame, which is quite slow.\n",
    "\n",
    "- I was originally using the first 44 layers of the inception network, so I tried the first 28 layers instead; that reduced the times somewhat, but it was still around 0.4s per frame on my old laptop, which was still quite slow. So I decided to try cutting the network before the first inception module, after just the convolutions. That has the frame times down to about 0.25s per frame, which seems to be just fast enough. It does drive noticeably better on my faster laptop, which has frame times just below 0.1s per frame. This is all on CPU (no GPU involved).\n",
    "\n",
    "- For good measure, since I don't have a lot of data to support my performance problem hypothesis, I decided to add in the extra training data that udacity released and to use the 'reflect horizontally' trick, which I saw mentioned on Slack. That increased the amount of training data (summary is below).\n",
    "\n",
    "## Request for Information if it Fails Again\n",
    "\n",
    "If it still doesn't drive, could you please include some of the `drive.py` output showing the timings in your review, so I can assess whether it was slower or faster than in my testing.\n",
    "\n",
    "It would also be helpful if you could confirm the settings used for the simulator: I have done all of my work on the lowest resolution with 'Fastest' quality.\n",
    "\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import platform\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "\n",
    "from common import * \n",
    "import bottleneck_features\n",
    "import preprocess\n",
    "import model_io\n",
    "import batch\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "\n",
    "The full inception model is too slow for real time use on my laptop, so I am just using the first few layers. Loading the whole inception model is also very slow, so cut out only the weights we need and save them for loading later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inception\n",
    "import model_io\n",
    "\n",
    "CUT_INDEX = 12 # layer 12 is before the first inception module\n",
    "\n",
    "if not os.path.exists(base_model_stem(CUT_INDEX) + '.json'):\n",
    "    model_io.save_model(\n",
    "        base_model_stem(CUT_INDEX) + '.json',\n",
    "        base_model_stem(CUT_INDEX) + '.h5',\n",
    "        inception.make_cut_model(CUT_INDEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_io.load_base_model(CUT_INDEX).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Correct the image file paths, since I have several driving logs in different folders.\n",
    "- Smooth the control inputs. The input from me is quite spikey, because all I can do is press a button or not. This seems like it would make learning quite difficult, so apply smoothing.\n",
    "- Bottleneck the features to make training reasonably fast.\n",
    "\n",
    "### Training (and Validation) Data\n",
    "\n",
    "I started out by driving around quite fast and cutting corners (`ccw_1` and `cw_1`) and then doing several laps with recovery, as suggested in the assignment spec. I did both clockwise and counterclockwise on the first training track.\n",
    "\n",
    "Model performance was not very good on the fast data, so I recorded some slower (roughly 10mph) data, trying to be very careful about staying in the middle of the road. Performance was much better on the slower datasets. (I later modified `drive.py` to keep the speed at about 10mph to match the training data.)\n",
    "\n",
    "The main place where the model had problems was with the turnout after the bridge. It would often drive into it, and I did not provide any training data in there, so it usually got lost and crashed. I recorded four more drives around that corner, and now at least some of the models turn correctly to avoid the turnout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log = pd.concat([\n",
    "    # preprocess.run('data/ccw_1', CUT_INDEX), # driving fairly aggressively\n",
    "    # preprocess.run('data/cw_1', CUT_INDEX),\n",
    "    preprocess.run('data/ccw_2', CUT_INDEX),\n",
    "    preprocess.run('data/cw_2', CUT_INDEX),\n",
    "    preprocess.run('data/ccw_recover_from_right_1', CUT_INDEX),\n",
    "    preprocess.run('data/ccw_recover_from_left_1', CUT_INDEX),\n",
    "    preprocess.run('data/cw_recover_from_right_1', CUT_INDEX),\n",
    "    preprocess.run('data/cw_recover_from_left_1', CUT_INDEX),\n",
    "    preprocess.run('data/ccw_turnout_1', CUT_INDEX),\n",
    "    preprocess.run('data/ccw_turnout_2', CUT_INDEX),\n",
    "    preprocess.run('data/udacity', CUT_INDEX, header=0, smooth=False)\n",
    "])\n",
    "print(log.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize_dataset():\n",
    "    groups = log.groupby('dataset')\n",
    "    totals = groups['center_image'].agg([len])\n",
    "    mean_speed = groups['speed'].mean()\n",
    "    mean_steering_angle = groups['steering_angle'].mean()\n",
    "    return pd.concat([totals, mean_speed, mean_steering_angle], axis=1)\n",
    "summarize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Images with Bottleneck Features\n",
    "\n",
    "Here are example images from a single frame. Images from each of the three cameras are included, together with their horizontal reflections. The first three feature channels for each image are also plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_example_images(index, num_channels):\n",
    "    log_batch = log.iloc[index:index + 1] # batch of one\n",
    "    bottleneck = batch.load_bottleneck_files(log_batch)[0]\n",
    "    images, column_names = bottleneck_features.make_batch_images(log_batch)\n",
    "    num_files = len(column_names)\n",
    "    fig, axes = plt.subplots(\n",
    "        num_files, num_channels + 1,\n",
    "        figsize=(3*(num_channels + 1), 2*num_files))\n",
    "    for i, column_name in enumerate(column_names):\n",
    "        axes[i][0].set_ylabel(column_name, rotation=90, size='large')\n",
    "        axes[i][0].imshow(images[i])\n",
    "        for j in range(num_channels):\n",
    "            axes[i][j + 1].imshow(bottleneck[column_name][:,:,j], cmap='gray')\n",
    "show_example_images(100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steering Angle Smoothing\n",
    "\n",
    "I tried two types of smoothing (implemented in `preprocess.py`):\n",
    "\n",
    "- Exponential smoothing: an exponential weighted moving average (`smooth_steering_angle_1`)\n",
    "- Gaussian smoothing: a 1D gaussian filter with sigma 3 (`smooth_steering_angle_gaussian_3`)\n",
    "\n",
    "Both seem to track pretty well, but the gaussian smoothing is better at preserving the mean steering angle and gave better results overall in the model. I also tried a sigma 5 gaussian, but results were worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_smooth_steering_angle():\n",
    "    df = log[['time', 'steering_angle', 'smooth_steering_angle_1', 'smooth_steering_angle_gaussian_3']]\n",
    "    df = df[:600]\n",
    "    df = df.set_index(['time'])\n",
    "    df.plot(figsize=(12, 6))\n",
    "plot_smooth_steering_angle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothed Steering Video\n",
    "\n",
    "To check that the datasets were sane, I made some videos (not included, since they are rather large --- there is a video below showing a prediction on `ccw_2`, which is included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def steering_angle_to_radians(steering_angle):\n",
    "    \"\"\"\n",
    "    The recorded steering angle ranges from -1 to 1.\n",
    "    In the sim, it gives values from -25 degrees to 25 degrees.\n",
    "    \"\"\"\n",
    "    return math.radians(steering_angle * 25.0)\n",
    "\n",
    "def draw_steering_angle(image, steering_angle, color, thickness=2):\n",
    "    bottom_x = image.shape[1] / 2.0\n",
    "    bottom_y = image.shape[0]\n",
    "    radius = bottom_y / 2.0\n",
    "    steering_angle_radians = steering_angle_to_radians(steering_angle)\n",
    "    top_x = bottom_x + radius * math.sin(steering_angle_radians)\n",
    "    top_y = bottom_y - radius * math.cos(steering_angle_radians)\n",
    "    bottom_x, bottom_y = int(round(bottom_x)), int(round(bottom_y))\n",
    "    top_x, top_y = int(round(top_x)), int(round(top_y))\n",
    "    cv2.line(image, (bottom_x, bottom_y), (top_x, top_y), color, thickness)\n",
    "\n",
    "def make_steering_movie(\n",
    "    filestem,\n",
    "    log,\n",
    "    smoothed_steering_angle_column,\n",
    "    predicted_steering_angle_column=None):\n",
    "    \n",
    "    if platform.system() == 'Linux':\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        filename = filestem + '.avi'\n",
    "    else:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')        \n",
    "        filename = filestem + '.mp4'\n",
    "    \n",
    "    input_color = [0, 0, 255]\n",
    "    smoothed_color = [0, 255, 0]\n",
    "    predicted_color = [255, 0, 0]\n",
    "    video = cv2.VideoWriter(filename, fourcc, 10, IMAGE_SHAPE[0:2][::-1])\n",
    "    for i in range(len(log)):\n",
    "#         if i % 50 == 0:\n",
    "#             print('frame', i)\n",
    "        image = imread(log['center_image'].values[i])\n",
    "        steering_angle = log['steering_angle'].values[i]\n",
    "        draw_steering_angle(image, steering_angle, input_color)\n",
    "\n",
    "        smoothed_steering_angle = log[smoothed_steering_angle_column].values[i]\n",
    "        draw_steering_angle(image, smoothed_steering_angle, smoothed_color)\n",
    "        \n",
    "        if predicted_steering_angle_column is not None:\n",
    "            predicted_steering_angle = log[predicted_steering_angle_column].values[i]\n",
    "            draw_steering_angle(image, predicted_steering_angle, predicted_color)\n",
    "\n",
    "        cv2.putText(image, log['center_image'].values[i],\n",
    "                    (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.1, 0)\n",
    "            \n",
    "        video.write(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    video.release()\n",
    "    \n",
    "for dataset in log['dataset'].unique():\n",
    "    make_steering_movie(os.path.join('data', dataset, 'check'),\n",
    "                        log[log['dataset'] == dataset][0:100],\n",
    "                        'smooth_steering_angle_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Bottleneck Features\n",
    "\n",
    "TODO UPDATE THESE\n",
    "\n",
    "How does the data look after passing through the first 44 layers of Inception V3? There are a lot of channels (256), but visualising a few of them shows that it's picking up edges and outlines of roads in at least some channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bottleneck_output(num_images, num_channels, image_stride=100):\n",
    "    fig, axes = plt.subplots(num_images, num_channels,\n",
    "                             figsize=(2*num_channels, 2*num_images),\n",
    "                             sharex=True, sharey=True)\n",
    "    for i in range(num_images):\n",
    "        index = i * image_stride\n",
    "        image = np.load(log['bottleneck_features'].values[index])['center_image']\n",
    "        for j in range(num_channels):\n",
    "            axes[i][j].imshow(image[:,:,j], cmap='gray')\n",
    "plot_bottleneck_output(3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model is defined in `model.py`. The layers and the sizes used for the submitted model are: \n",
    "\n",
    "1. Inputs: 17 x 37 x 256 bottleneck features from layer 44 of the InceptionV3 network\n",
    "1. 1x1 convolution with 64 filters to reduce the dimensionality of the bottleneck features, in order to make the model a more manageable size.\n",
    "1. Flatten\n",
    "1. Dense fully connected layer with tanh activation (empirically better than relu; see Appendix).\n",
    "1. Dense output laye rwith a single output, namely the steering angle.\n",
    "\n",
    "The submitted network was one of many networks tested in the simulator (see Appendix). Using these parameters does not always produce a particularly good network; there is a fairly large amount of randomness in the training.\n",
    "\n",
    "### Training / Validation Split and Batches\n",
    "\n",
    "The bottleneck features (and corresponding labels) are shuffled and then split. To improve performance, we save one batch per `npz` file, so we can just load a single batch at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_params = {\n",
    "    'cut_index': CUT_INDEX,\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 42,\n",
    "    'batch_size': 128,\n",
    "    'label_column': 'smooth_steering_angle_gaussian_3',\n",
    "    'side_camera_bias': 1.5/25,\n",
    "    'flip': True,\n",
    "}\n",
    "nb_train, batch_files_train, nb_val, batch_files_val = \\\n",
    "batch.make_train_val_batches(log, batch_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Training uses the Adam optimizer with its default parameters.\n",
    "\n",
    "The model includes L2 regularization on the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "steering_model = model.build(\n",
    "    input_shape=np.load(log['bottleneck_features'].values[0])['center_image'].shape,\n",
    "    nb_filter=8,\n",
    "    nb_hidden=128,\n",
    "    l2_weight=0.01,\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "history = model.train(\n",
    "    steering_model,\n",
    "    nb_epoch=20,\n",
    "    patience=2,\n",
    "    nb_train=nb_train,\n",
    "    batch_files_train=batch_files_train,\n",
    "    nb_val=nb_val,\n",
    "    batch_files_val=batch_files_val,\n",
    "    save_stem='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model with best validation loss\n",
    "steering_model = model_io.load_model('model.json', 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_prefix_prediction(end):\n",
    "    df = log[:600].copy()\n",
    "    df['predicted_steering_angle'] = steering_model.predict_on_batch(\n",
    "        batch.make_batch(\n",
    "            df,\n",
    "            label_column=batch_params['label_column'],\n",
    "            side_camera_bias=None,\n",
    "            flip=False)[0])\n",
    "    return df\n",
    "log_prefix_with_prediction = make_prefix_prediction(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_predicted_steering_angle():\n",
    "    df = log_prefix_with_prediction[\n",
    "        ['time', 'steering_angle', batch_params['label_column'], 'predicted_steering_angle']]\n",
    "    df = df.set_index(['time'])\n",
    "    df.plot(figsize=(12, 6))\n",
    "plot_predicted_steering_angle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a video showing performance on the first part of the dataset. The colors in the video are:\n",
    "\n",
    "- blue: actual (unsmoothed) steering input in the training data\n",
    "- green: smoothed input in the training data (gaussian 3 sigma)\n",
    "- red: predicted steering angle\n",
    "\n",
    "Note: if it doesn't embed, here is a link: [test.avi](test.avi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_steering_movie('test', log_prefix_with_prediction, batch_params['label_column'], 'predicted_steering_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"320\" height=\"160\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('test.avi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Experiment Notes and Parameter Sweeps\n",
    "\n",
    "\n",
    "## Experiments with Unsmoothed Steering Angles\n",
    "\n",
    "- Tried just adding a linear model (32--128 units, L2 regularization with weights 0.001--0.01) after the 1x1 convolution, but validation loss generally bottomed out at about MSE 0.04, which is too high. It also tended to diverge, at least with the Adam optimizer.\n",
    "- Tried adding a hidden layer (32-128 units) with ReLU activation and dropout before the linear layer, but that seemed to just predict a small constant steering angle most of the time. Maybe a \"dying relus\" problem. It seems you can get an MSE around 0.05 by just predicting a constant near zero all the time.\n",
    "- So I tried tanh activation instead, but that did not seem to help.\n",
    "- I switched back to L2 regularization with ReLUs, which did a bit better but still understeered.\n",
    "- I think the problem is that it's too easy to just ignore my occasional steering inputs (key presses).\n",
    "\n",
    "## Experiments with Smoothed Steering Angles\n",
    "\n",
    "- Tried the linear model again. No longer predicting constants, but it starts overfitting (increase in validation loss) after only a couple of epochs. Probably going to need something more expressive.\n",
    "- Tried adding hidden layer (32 units) with ReLU activation and L2 regularization (weight 0.01). Still mostly predicting a small constant.\n",
    "- Tried tanh activation on the hidden layer. Now it seems much happier: getting to the bridge and MSE 0.015 with nb_filter=64, nb_hidden=32 and l2_weight=0.01. Still understeering a bit on gentler bends.\n",
    "- Tried reducing L2 weight to 0.005. That seemed to slow down training quite a lot; got to MSE 0.017 after 16 epochs. Still understeering and weaving a bit.\n",
    "- Tried mean absolute error instead of mean squared error, since all of the errors are actually pretty small. New record on first run: made it to the turnout but didn't turn left. MAE 0.0611. Some weaving, but much less understeer. Much better fit in the steering prediction plot; good to see that better fit corresponds to better performance in this case. Adam optimizer diverged after 3 epochs, however.\n",
    "- Tried increasing regularization back to 0.01. That seems to make it get stuck on a constant again.\n",
    "- Tried putting regularization back to 0.005 but using Adagrad instead of Adam. Still getting stuck. Subsequent runs with Adam also getting stuck. Looks like I just got lucky that first time.\n",
    "- Then I tried shrinking the initialization weights (using a normal distribution with scale 0.1). Since doing that, I've had much better luck with convergence.\n",
    "\n",
    "## Parameter Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# From http://stackoverflow.com/a/40623158/2053820\n",
    "def dict_product(dicts):\n",
    "    \"\"\"\n",
    "    >>> list(dict_product(dict(number=[1,2], character='ab')))\n",
    "    [{'character': 'a', 'number': 1},\n",
    "     {'character': 'a', 'number': 2},\n",
    "     {'character': 'b', 'number': 1},\n",
    "     {'character': 'b', 'number': 2}]\n",
    "    \"\"\"\n",
    "    return (dict(zip(dicts, x)) for x in itertools.product(*dicts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def search():\n",
    "    results_file = 'grid.pickle'\n",
    "    if os.path.isfile(results_file):\n",
    "        with open(results_file, 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "    else:\n",
    "        results = {}\n",
    "    \n",
    "    keys = {\n",
    "        'cut_index': [CUT_INDEX],\n",
    "        'version': [5],\n",
    "        'nb_epoch': [30],\n",
    "        'side_camera_bias': [1.5/25],\n",
    "        'flip': [True],\n",
    "        'label_column': ['smooth_steering_angle_gaussian_3'],\n",
    "        'batch_size': [128],\n",
    "        'nb_filter': [4, 8, 16],\n",
    "        'nb_hidden': [32, 64, 128],\n",
    "        'l2_weight': [0.01, 0.02],\n",
    "        'optimizer': ['adam']\n",
    "    }\n",
    "    \n",
    "    input_shape = np.load(log['bottleneck_features'].values[0])['center_image'].shape\n",
    "\n",
    "    for key in dict_product(keys):\n",
    "        print(key)\n",
    "        frozen_key = frozenset(key.items())\n",
    "        if frozen_key in results:\n",
    "            continue\n",
    "        print('Running...')\n",
    "        \n",
    "        batch_params = {\n",
    "            param: key[param] for param in ['batch_size', 'label_column', 'side_camera_bias', 'flip', 'cut_index']\n",
    "        }\n",
    "        batch_params['random_state'] = 42\n",
    "        batch_params['test_size'] = 0.2\n",
    "        \n",
    "        nb_train, batch_files_train, nb_val, batch_files_val = \\\n",
    "            batch.make_train_val_batches(log, batch_params)\n",
    "        \n",
    "        key_stem = os.path.join('models', make_filestem('grid_model', key))\n",
    "        model_json = key_stem + '.json'\n",
    "        model_weights_h5 = key_stem + '.h5'\n",
    "        \n",
    "        key = key.copy()\n",
    "        del key['version']\n",
    "        \n",
    "        steering_model = model.build(\n",
    "            input_shape,\n",
    "            nb_filter=key.pop('nb_filter'),\n",
    "            nb_hidden=key.pop('nb_hidden'),\n",
    "            l2_weight=key.pop('l2_weight'),\n",
    "            optimizer=key.pop('optimizer'))\n",
    "\n",
    "        history = model.train(\n",
    "            steering_model,\n",
    "            nb_epoch=key.pop('nb_epoch'),\n",
    "            patience=2,\n",
    "            nb_train=nb_train,\n",
    "            batch_files_train=batch_files_train,\n",
    "            nb_val=nb_val,\n",
    "            batch_files_val=batch_files_val,\n",
    "            save_stem=key_stem)\n",
    "       \n",
    "        steering_model.load_weights(model_weights_h5) # best weights\n",
    "        \n",
    "        model_io.save_model(model_json, model_weights_h5, steering_model)\n",
    "                    \n",
    "        results[frozen_key] = {\n",
    "            'history': history.history,\n",
    "            'model_json': model_json,\n",
    "            'model_weights_h5': model_weights_h5\n",
    "        }\n",
    "        \n",
    "        with open(results_file, 'wb') as f:\n",
    "            pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return results\n",
    "\n",
    "grid = search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize_grid(grid, val_loss_threshold):\n",
    "    \"\"\"\n",
    "    Print out the more promising hyperparameters from a search, according to\n",
    "    validation loss.\n",
    "    \"\"\"\n",
    "    best_val_loss = 1e9\n",
    "    best_params = None\n",
    "    items = sorted(grid, key = lambda k: min(grid[k]['history']['val_loss']))\n",
    "    for frozen_key in items:\n",
    "        value = grid[frozen_key]\n",
    "        key = dict(frozen_key)\n",
    "        val_loss = value['history']['val_loss']\n",
    "        min_val_loss = min(val_loss)\n",
    "        nb_epochs = len(val_loss)\n",
    "        if min_val_loss < val_loss_threshold:\n",
    "            print(key, min_val_loss, nb_epochs)\n",
    "            print('cp', value['model_json'], 'model.json')\n",
    "            print('cp', value['model_weights_h5'], 'model.h5')\n",
    "            print('python drive.py model.json')\n",
    "            print()\n",
    "        if min_val_loss < best_val_loss:\n",
    "            best_val_loss = min_val_loss\n",
    "            best_params = key\n",
    "    print('BEST:', best_params, best_val_loss)\n",
    "summarize_grid(grid, 0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notes:\n",
    "# The ones with lowest MAE show a lot of weave.\n",
    "\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'nb_filter': 16, 'l2_weight': 0.005, 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0486434253 30\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 4, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0497479700963 14\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 8, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0505109161774 15\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 64, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0506108435425 25\n",
    "\n",
    "# PASS... but failed when double checked\n",
    "# {'version': 5, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 32, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0633698049717 6\n",
    "\n",
    "# PASS: a bit of weave early on, but recovered\n",
    "# {'nb_filter': 16, 'nb_epoch': 30, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0603575362906 8\n",
    "\n",
    "# PASS: a bit tight on the turnout turn and some weave, but pretty good.\n",
    "# {'nb_filter': 8, 'nb_epoch': 30, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.060572350685 11\n",
    "\n",
    "# A bit better but still weaves a lot\n",
    "# 'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 8, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0507841391891 30\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 8, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0520709987096 14\n",
    "\n",
    "# Made it to the turnout; pretty stable\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 4, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0539738734781 11\n",
    "\n",
    "# Weaves, but made it almost to the turnout.\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 32, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0546632729836 11\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 64, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0547469570021 15\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 4, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0563107190402 11\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 32, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0564398219643 13\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 64, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0569417894736 19\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'nb_filter': 16, 'l2_weight': 0.005, 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0572153125485 12\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 8, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0572628182225 10\n",
    "\n",
    "# Made it to the turnout; pretty stable.\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 8, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.057351532648 11\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 4, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0574356182614 14\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'nb_filter': 16, 'l2_weight': 0.01, 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0575831151575 10\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'nb_filter': 16, 'l2_weight': 0.005, 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0576822490848 7\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'nb_filter': 16, 'l2_weight': 0.01, 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0581040763912 10\n",
    "\n",
    "# End of bridge, but weaves\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 4, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0583697665036 8\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 32, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0585662010462 7\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 64, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0586640624298 19\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 4, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0604852065088 11\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.01, 'nb_filter': 32, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0624602926608 6\n",
    "\n",
    "# Some weave, did not turn at turnout.\n",
    "# {'nb_filter': 4, 'nb_epoch': 30, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0530055659274 25\n",
    "\n",
    "# Some weave, did not turn at turnout.\n",
    "# {'nb_filter': 16, 'nb_epoch': 30, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.01} 0.0536798351864 30\n",
    "\n",
    "# Pretty good but hit edge near turnout. Marginal pass.\n",
    "# {'nb_filter': 8, 'nb_epoch': 30, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0564248780002 13\n",
    "\n",
    "# Pretty good, did not turn at turnout.\n",
    "# {'nb_filter': 4, 'nb_epoch': 30, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0581461225773 22\n",
    "\n",
    "# Lost it on the bridge\n",
    "# {'nb_filter': 4, 'nb_epoch': 30, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0594900304391 14\n",
    "\n",
    "# Pretty good, did not turn at turnout.\n",
    "# {'nb_filter': 16, 'nb_epoch': 30, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0595571538155 11\n",
    "\n",
    "# Pretty good, did not turn at turnout.\n",
    "# {'nb_filter': 8, 'nb_epoch': 30, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.01} 0.0601387542259 14\n",
    "\n",
    "# Pretty good, did not turn at turnout.\n",
    "# {'nb_filter': 64, 'nb_epoch': 30, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0617620240928 15\n",
    "\n",
    "# Pretty good, did not turn at turnout.\n",
    "# {'nb_filter': 32, 'nb_epoch': 30, 'nb_hidden': 32, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0625045372937 8\n",
    "\n",
    "# A bit of weave, did not turn at turnout.\n",
    "# {'nb_filter': 16, 'nb_epoch': 30, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0627611787279 10\n",
    "\n",
    "# A bit of weave, did not turn at turnout.\n",
    "# {'nb_filter': 32, 'nb_epoch': 30, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0627763003509 16\n",
    "\n",
    "# A bit of weave, did not turn at turnout.\n",
    "# {'nb_filter': 8, 'nb_epoch': 30, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0632025661513 10\n",
    "\n",
    "# A bit of weave, did not turn at turnout.\n",
    "# {'nb_filter': 64, 'nb_epoch': 30, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.01} 0.0632899765945 9\n",
    "\n",
    "# Pretty good, did not turn at turnout.\n",
    "# {'nb_filter': 64, 'nb_epoch': 30, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0649442658476 11\n",
    "\n",
    "# Weaves.\n",
    "# {'nb_filter': 64, 'nb_epoch': 30, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.0674919454212 9\n",
    "\n",
    "# Weaves\n",
    "# {'nb_filter': 32, 'nb_epoch': 30, 'nb_hidden': 64, 'side_camera_bias': 0.06, 'version': 5, 'optimizer': 'adam', 'batch_size': 128, 'label_column': 'smooth_steering_angle_gaussian_3', 'l2_weight': 0.02} 0.067675512434 5\n",
    "\n",
    "# Weaves\n",
    "# {'version': 5, 'nb_hidden': 128, 'side_camera_bias': 0.06, 'batch_size': 128, 'l2_weight': 0.005, 'nb_filter': 64, 'label_column': 'smooth_steering_angle_gaussian_3', 'nb_epoch': 30, 'optimizer': 'adam'} 0.0645840176195 9"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
