{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import platform\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "\n",
    "from common import * \n",
    "import preprocess\n",
    "import model_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "\n",
    "The full inception model is too slow for real time use on my laptop, so I am just using the first few layers.\n",
    "\n",
    "Loading the whole inception model is also very slow, so cut out only the weights we need and save them for loading later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inception\n",
    "import model_io\n",
    "\n",
    "CUT_INDEX=44\n",
    "\n",
    "if not os.path.exists(base_model_stem(CUT_INDEX) + '.json'):\n",
    "    model_io.save_model(\n",
    "        base_model_stem(CUT_INDEX) + '.json',\n",
    "        base_model_stem(CUT_INDEX) + '.h5',\n",
    "        inception.make_cut_model(CUT_INDEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 160, 320, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 79, 159, 32)   896         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 79, 159, 32)   64          convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 77, 157, 32)   9248        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 77, 157, 32)   64          convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 77, 157, 64)   18496       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 77, 157, 64)   128         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 38, 78, 64)    0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 38, 78, 80)    5200        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 38, 78, 80)    160         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 36, 76, 192)   138432      batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 36, 76, 192)   384         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 17, 37, 192)   0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 17, 37, 64)    12352       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 17, 37, 64)    128         convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 17, 37, 48)    9264        maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 17, 37, 96)    55392       batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 17, 37, 48)    96          convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 17, 37, 96)    192         convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_1 (AveragePooli (None, 17, 37, 192)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 17, 37, 64)    12352       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 17, 37, 64)    76864       batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 17, 37, 96)    83040       batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 17, 37, 32)    6176        averagepooling2d_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 17, 37, 64)    128         convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 17, 37, 64)    128         convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 17, 37, 96)    192         convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 17, 37, 32)    64          convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Merge)                   (None, 17, 37, 256)   0           batchnormalization_6[0][0]       \n",
      "                                                                   batchnormalization_8[0][0]       \n",
      "                                                                   batchnormalization_11[0][0]      \n",
      "                                                                   batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 17, 37, 64)    16448       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNorm (None, 17, 37, 64)    128         convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 17, 37, 48)    12336       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 17, 37, 96)    55392       batchnormalization_16[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNorm (None, 17, 37, 48)    96          convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNorm (None, 17, 37, 96)    192         convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_2 (AveragePooli (None, 17, 37, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 17, 37, 64)    16448       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 17, 37, 64)    76864       batchnormalization_14[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 17, 37, 96)    83040       batchnormalization_17[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 17, 37, 32)    8224        averagepooling2d_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_13 (BatchNorm (None, 17, 37, 64)    128         convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorm (None, 17, 37, 64)    128         convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNorm (None, 17, 37, 96)    192         convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNorm (None, 17, 37, 32)    64          convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Merge)                   (None, 17, 37, 256)   0           batchnormalization_13[0][0]      \n",
      "                                                                   batchnormalization_15[0][0]      \n",
      "                                                                   batchnormalization_18[0][0]      \n",
      "                                                                   batchnormalization_19[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 699120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_io.load_base_model(CUT_INDEX).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "- Correct the image file paths, since I have several driving logs in different folders.\n",
    "- Smooth the control inputs. The input from me is quite spikey, because all I can do is press a button or not. This seems like it would make learning quite difficult, so apply smoothing.\n",
    "- Bottleneck the features to make training reasonably fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0\n",
      "index 50\n"
     ]
    }
   ],
   "source": [
    "log = pd.concat([\n",
    "#     preprocess.run('data/ccw_1', CUT_INDEX),\n",
    "#     preprocess.run('data/cw_1', CUT_INDEX),\n",
    "    preprocess.run('data/ccw_2', CUT_INDEX),\n",
    "    preprocess.run('data/cw_2', CUT_INDEX),\n",
    "    preprocess.run('data/ccw_recover_from_right_1', CUT_INDEX),\n",
    "    preprocess.run('data/ccw_recover_from_left_1', CUT_INDEX),\n",
    "    preprocess.run('data/cw_recover_from_right_1', CUT_INDEX),\n",
    "    preprocess.run('data/cw_recover_from_left_1', CUT_INDEX)\n",
    "])\n",
    "print(log.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize_dataset():\n",
    "    groups = log.groupby('dataset')\n",
    "    totals = groups['center_image'].agg([len])\n",
    "    mean_speed = groups['speed'].mean()\n",
    "    mean_steering_angle = groups['steering_angle'].mean()\n",
    "    return pd.concat([totals, mean_speed, mean_steering_angle], axis=1)\n",
    "summarize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "I tried two types of smoothing:\n",
    "\n",
    "- Exponential smoothing: an exponential weighted moving average\n",
    "- Gaussian smoothing: a 1D gaussian filter\n",
    "\n",
    "Both seem to track pretty well, but the gaussian smoothing is better at preserving the mean steering angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_smooth_steering_angle():\n",
    "    df = log[['time', 'steering_angle', 'smooth_steering_angle_1', 'smooth_steering_angle_gaussian_3']]\n",
    "    df = df[:600]\n",
    "    df = df.set_index(['time'])\n",
    "    df.plot(figsize=(12, 6))\n",
    "plot_smooth_steering_angle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steering Angle Bias\n",
    "\n",
    "We don't want a lot of bias in the training data. Or maybe this isn't that important... I don't really know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('raw steering angle bias:', np.mean(log['steering_angle']))\n",
    "print('exponentially smoothed steering angle bias:', np.mean(log['smooth_steering_angle_1']))\n",
    "print('gaussian smoothed steering angle bias:', np.mean(log['smooth_steering_angle_gaussian_5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bottleneck_output(num_images, num_channels, image_stride=50):\n",
    "    fig, axes = plt.subplots(num_images, num_channels,\n",
    "                             figsize=(2*num_channels, 2*num_images),\n",
    "                             sharex=True, sharey=True)\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_channels):\n",
    "            index = i * image_stride\n",
    "            image = np.load(log['bottleneck_features'].values[i])['center_image']\n",
    "            axes[i][j].imshow(image[:,:,j], cmap='gray')\n",
    "plot_bottleneck_output(3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothed Steering Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def steering_angle_to_radians(steering_angle):\n",
    "    \"\"\"\n",
    "    The recorded steering angle ranges from -1 to 1.\n",
    "    In the sim, it gives values from -25 degrees to 25 degrees.\n",
    "    \"\"\"\n",
    "    return math.radians(steering_angle * 25.0)\n",
    "\n",
    "def draw_steering_angle(image, steering_angle, color, thickness=2):\n",
    "    bottom_x = image.shape[1] / 2.0\n",
    "    bottom_y = image.shape[0]\n",
    "    radius = bottom_y / 2.0\n",
    "    steering_angle_radians = steering_angle_to_radians(steering_angle)\n",
    "    top_x = bottom_x + radius * math.sin(steering_angle_radians)\n",
    "    top_y = bottom_y - radius * math.cos(steering_angle_radians)\n",
    "    bottom_x, bottom_y = int(round(bottom_x)), int(round(bottom_y))\n",
    "    top_x, top_y = int(round(top_x)), int(round(top_y))\n",
    "    cv2.line(image, (bottom_x, bottom_y), (top_x, top_y), color, thickness)\n",
    "\n",
    "def make_steering_movie(\n",
    "    filestem,\n",
    "    log,\n",
    "    smoothed_steering_angle_column,\n",
    "    predicted_steering_angle_column=None):\n",
    "    \n",
    "    if platform.system() == 'Linux':\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        filename = filestem + '.avi'\n",
    "    else:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')        \n",
    "        filename = filestemp + '.mp4'\n",
    "    \n",
    "    input_color = [0, 0, 255]\n",
    "    smoothed_color = [0, 255, 0]\n",
    "    predicted_color = [255, 0, 0]\n",
    "    video = cv2.VideoWriter(filename, fourcc, 10, IMAGE_SHAPE[0:2][::-1])\n",
    "    for i in range(len(log)):\n",
    "        if i % 50 == 0:\n",
    "            print('frame', i)\n",
    "        image = imread(log['center_image'].values[i])\n",
    "        steering_angle = log['steering_angle'].values[i]\n",
    "        draw_steering_angle(image, steering_angle, input_color)\n",
    "\n",
    "        smoothed_steering_angle = log[smoothed_steering_angle_column].values[i]\n",
    "        draw_steering_angle(image, smoothed_steering_angle, smoothed_color)\n",
    "        \n",
    "        if predicted_steering_angle_column is not None:\n",
    "            predicted_steering_angle = log[predicted_steering_angle_column].values[i]\n",
    "            draw_steering_angle(image, predicted_steering_angle, predicted_color)\n",
    "\n",
    "        cv2.putText(image, log['center_image'].values[i],\n",
    "                    (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 0)\n",
    "            \n",
    "        video.write(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    video.release()\n",
    "    \n",
    "for dataset in log['dataset'].unique():\n",
    "    make_steering_movie(os.path.join('data', dataset, 'check'),\n",
    "                        log[log['dataset'] == dataset][0:100],\n",
    "                        'smooth_steering_angle_1')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "- I put a 1x1 convolution up front to reduce the depth, in order to make the model a more manageable size.\n",
    "\n",
    "## Experiments with Unsmoothed Steering Angles\n",
    "\n",
    "- Tried just adding a linear model (32--128 units, L2 regularization with weights 0.001--0.01) after the 1x1 convolution, but validation loss generally bottomed out at about MSE 0.04, which is too high. It also tended to diverge, at least with the Adam optimizer.\n",
    "- Tried adding a hidden layer (32-128 units) with ReLU activation and dropout before the linear layer, but that seemed to just predict a small constant steering angle most of the time. Maybe a \"dying relus\" problem. It seems you can get an MSE around 0.05 by just predicting a constant near zero all the time.\n",
    "- So I tried tanh activation instead, but that did not seem to help.\n",
    "- I switched back to L2 regularization with ReLUs, which did a bit better but still understeered.\n",
    "- I think the problem is that it's too easy to just ignore my occasional steering inputs (key presses).\n",
    "\n",
    "## Experiments with Smoothed Steering Angles\n",
    "\n",
    "- Tried the linear model again. No longer predicting constants, but it starts overfitting (increase in validation loss) after only a couple of epochs. Probably going to need something more expressive.\n",
    "- Tried adding hidden layer (32 units) with ReLU activation and L2 regularization (weight 0.01). Still mostly predicting a small constant.\n",
    "- Tried tanh activation on the hidden layer. Now it seems much happier: getting to the bridge and MSE 0.015 with nb_filter=64, nb_hidden=32 and l2_weight=0.01. Still understeering a bit on gentler bends.\n",
    "- Tried reducing L2 weight to 0.005. That seemed to slow down training quite a lot; got to MSE 0.017 after 16 epochs. Still understeering and weaving a bit.\n",
    "- Tried mean absolute error instead of mean squared error, since all of the errors are actually pretty small. New record on first run: made it to the turnout but didn't turn left. MAE 0.0611. Some weaving, but much less understeer. Much better fit in the steering prediction plot; good to see that better fit corresponds to better performance in this case. Adam optimizer diverged after 3 epochs, however.\n",
    "- Tried increasing regularization back to 0.01. That seems to make it get stuck on a constant again.\n",
    "- Tried putting regularization back to 0.005 but using Adagrad instead of Adam. Still getting stuck. Subsequent runs with Adam also getting stuck. Looks like I just got lucky that first time.\n",
    "\n",
    "Hall of fame:\n",
    "- models/grid_model_nb_hidden-32label_column-smooth_steering_angle_gaussian_3l2_weight-0.001nb_epoch-30batch_size-128nb_filter-64side_camera_bias-optimizer-adagradversion-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steering_model = model.build(\n",
    "    input_shape=np.load(log['bottleneck_features'].values[0])['center_image'].shape,\n",
    "    nb_filter=64,\n",
    "    nb_hidden=32,\n",
    "    l2_weight=0.005,\n",
    "    optimizer='adam'\n",
    "#     drop_prob=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = model.train(\n",
    "    steering_model, log,\n",
    "    label_column='smooth_steering_angle_gaussian_3',\n",
    "    test_size=0.2,\n",
    "    nb_epoch=20,\n",
    "    batch_size=128,\n",
    "    side_camera_bias=None,\n",
    "    save_stem='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model with best validation loss\n",
    "steering_model = model_io.load_model('model.json', 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log['predicted_steering_angle'] = steering_model.predict_generator(\n",
    "    model.generate_data(log),\n",
    "    val_samples=len(log)\n",
    ").flatten()\n",
    "print('raw MSE',\n",
    "    ((log['steering_angle'] - log['predicted_steering_angle'])**2).mean())\n",
    "print('smoothed MSE',\n",
    "    ((log['smooth_steering_angle_gaussian_3'] - log['predicted_steering_angle'])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_predicted_steering_angle():\n",
    "    df = log[['time', 'steering_angle', 'smooth_steering_angle_gaussian_3', 'predicted_steering_angle']]\n",
    "    df = df[:600]\n",
    "    df = df.set_index(['time'])\n",
    "    df.plot(figsize=(12, 6))\n",
    "plot_predicted_steering_angle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_steering_movie('test', log[0:500], 'smooth_steering_angle_1', 'predicted_steering_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# From http://stackoverflow.com/a/40623158/2053820\n",
    "def dict_product(dicts):\n",
    "    \"\"\"\n",
    "    >>> list(dict_product(dict(number=[1,2], character='ab')))\n",
    "    [{'character': 'a', 'number': 1},\n",
    "     {'character': 'a', 'number': 2},\n",
    "     {'character': 'b', 'number': 1},\n",
    "     {'character': 'b', 'number': 2}]\n",
    "    \"\"\"\n",
    "    return (dict(zip(dicts, x)) for x in itertools.product(*dicts.values()))\n",
    "\n",
    "def make_model_key_stem(key):\n",
    "    stem = os.path.join('models', 'grid_model_')\n",
    "    for param, value in key.items():\n",
    "        if value is None: value = ''\n",
    "        stem += param + '-' + str(value)\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def search():\n",
    "    results_file = 'grid.pickle'\n",
    "    if os.path.isfile(results_file):\n",
    "        with open(results_file, 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "    else:\n",
    "        results = {}\n",
    "    \n",
    "    keys = {\n",
    "        'version': [2,3,4],\n",
    "        'nb_epoch': [30],\n",
    "        'side_camera_bias': [None],\n",
    "        'label_column': ['smooth_steering_angle_gaussian_3'],\n",
    "        'batch_size': [128],\n",
    "        'nb_filter': [64, 128],\n",
    "        'nb_hidden': [64, 32],\n",
    "        'l2_weight': [0.001, 0.005, 0.01],\n",
    "        'optimizer': ['adam', 'adagrad']\n",
    "    }\n",
    "    \n",
    "    input_shape = np.load(log['bottleneck_features'].values[0])['center_image'].shape\n",
    "        \n",
    "    for key in dict_product(keys):\n",
    "        print(key)\n",
    "        frozen_key = frozenset(key.items())\n",
    "        if frozen_key in results:\n",
    "            continue\n",
    "        print('Running...')\n",
    "        \n",
    "        key_stem = make_model_key_stem(key)\n",
    "        model_json = key_stem + '.json'\n",
    "        model_weights_h5 = key_stem + '.h5'\n",
    "        \n",
    "        key = key.copy()\n",
    "        del key['version']\n",
    "        \n",
    "        steering_model = model.build(\n",
    "            input_shape,\n",
    "            nb_filter=key.pop('nb_filter'),\n",
    "            nb_hidden=key.pop('nb_hidden'),\n",
    "            l2_weight=key.pop('l2_weight'),\n",
    "            optimizer=key.pop('optimizer'))\n",
    "        \n",
    "        history = model.train(\n",
    "            steering_model,\n",
    "            log,\n",
    "            label_column=key.pop('label_column'),\n",
    "            test_size=0.2,\n",
    "            nb_epoch=key.pop('nb_epoch'),\n",
    "            batch_size=key.pop('batch_size'),\n",
    "            side_camera_bias=key.pop('side_camera_bias'),\n",
    "            save_stem=key_stem)\n",
    "        \n",
    "        steering_model.load_weights(model_weights_h5) # best weights\n",
    "        \n",
    "        model_io.save_model(model_json, model_weights_h5, steering_model)\n",
    "                    \n",
    "        results[frozen_key] = {\n",
    "            'history': history.history,\n",
    "            'model_json': model_json,\n",
    "            'model_weights_h5': model_weights_h5\n",
    "        }\n",
    "        \n",
    "        with open(results_file, 'wb') as f:\n",
    "            pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return results  \n",
    "\n",
    "grid = search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO\n",
    "\n",
    "- there is a wiggle in ccw_recover_from_left_1 at about 0:42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize_grid(grid, val_loss_threshold):\n",
    "    \"\"\"\n",
    "    Print out the more promising hyperparameters from a search, according to\n",
    "    validation loss.\n",
    "    \"\"\"\n",
    "    best_val_loss = 1e9\n",
    "    best_params = None\n",
    "    items = sorted(grid, key = lambda k: min(grid[k]['history']['val_loss']))\n",
    "    for frozen_key in items:\n",
    "        value = grid[frozen_key]\n",
    "        key = dict(frozen_key)\n",
    "        val_loss = value['history']['val_loss']\n",
    "        min_val_loss = min(val_loss)\n",
    "        nb_epochs = len(val_loss)\n",
    "        if min_val_loss < val_loss_threshold:\n",
    "            print(key, min_val_loss, nb_epochs)\n",
    "            print('cp', value['model_json'], 'model.json')\n",
    "            print('cp', value['model_weights_h5'], 'model.h5')\n",
    "            print('python drive.py model.json')\n",
    "            print()\n",
    "        if min_val_loss < best_val_loss:\n",
    "            best_val_loss = min_val_loss\n",
    "            best_params = key\n",
    "    print('BEST:', best_params, best_val_loss)\n",
    "summarize_grid(grid, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_file = 'grid.pickle'\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'rb') as f:\n",
    "        grid = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
